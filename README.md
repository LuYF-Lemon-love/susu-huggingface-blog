# susu-huggingface-blog

é˜…è¯»è¿‡çš„ HuggingFace çš„åšå®¢

## åšå®¢

|Huggingface è‹±æ–‡åšå®¢é¡µé¢|Huggingface ä¸­æ–‡åšå®¢åœ°å€|ä»“åº“ä¸­æ–‡åšå®¢åœ°å€|
|:-:|:-:|:-:|
|[Illustrating Reinforcement Learning from Human Feedback (RLHF)](https://huggingface.co/blog/rlhf)|[ChatGPT èƒŒåçš„â€œåŠŸè‡£â€â€”â€”RLHF æŠ€æœ¯è¯¦è§£](https://huggingface.co/blog/zh/rlhf)|[ChatGPT èƒŒåçš„â€œåŠŸè‡£â€â€”â€”RLHF æŠ€æœ¯è¯¦è§£](./zh/00001_rlhf.md)|
|[Fine-tune Llama 2 with DPO](https://huggingface.co/blog/dpo-trl)|[ä½¿ç”¨ DPO å¾®è°ƒ Llama 2](https://huggingface.co/blog/zh/dpo-trl)|[ä½¿ç”¨ DPO å¾®è°ƒ Llama 2](./zh/00002_dpo-trl.md)|
|[Optimizing your LLM in production](https://huggingface.co/blog/optimize-llm)|[é¢å‘ç”Ÿäº§çš„ LLM ä¼˜åŒ–](https://huggingface.co/blog/zh/optimize-llm)|[é¢å‘ç”Ÿäº§çš„ LLM ä¼˜åŒ–](./zh/00003_optimize-llm.md)|
|[StackLLaMA: A hands-on guide to train LLaMA with RLHF](https://huggingface.co/blog/stackllama)|[â€œStackLLaMAâ€: ç”¨ RLHF è®­ç»ƒ LLaMA çš„æ‰‹æŠŠæ‰‹æ•™ç¨‹](https://huggingface.co/blog/zh/stackllama)|[â€œStackLLaMAâ€: ç”¨ RLHF è®­ç»ƒ LLaMA çš„æ‰‹æŠŠæ‰‹æ•™ç¨‹](./zh/00004_stackllama.md)|
|[Open-source LLMs as LangChain Agents](https://huggingface.co/blog/open-source-llms-as-agents)|[å¼€æºå¤§è¯­è¨€æ¨¡å‹ä½œä¸º LangChain æ™ºèƒ½ä½“](https://huggingface.co/blog/zh/open-source-llms-as-agents)|[å¼€æºå¤§è¯­è¨€æ¨¡å‹ä½œä¸º LangChain æ™ºèƒ½ä½“](./zh/00005_open-source-llms-as-agents.md)|
|[ğŸ¤— PEFT: Parameter-Efficient Fine-Tuning of Billion-Scale Models on Low-Resource Hardware](https://huggingface.co/blog/peft)|[ğŸ¤— PEFTï¼šåœ¨ä½èµ„æºç¡¬ä»¶ä¸Šå¯¹åäº¿è§„æ¨¡æ¨¡å‹è¿›è¡Œå‚æ•°é«˜æ•ˆå¾®è°ƒ](https://huggingface.co/blog/zh/peft)|[ğŸ¤— PEFTï¼šåœ¨ä½èµ„æºç¡¬ä»¶ä¸Šå¯¹åäº¿è§„æ¨¡æ¨¡å‹è¿›è¡Œå‚æ•°é«˜æ•ˆå¾®è°ƒ](./zh/00006_peft.md)|